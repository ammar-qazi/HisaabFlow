"""
Modular Data Cleaner
Main orchestration class for data cleaning pipeline
Coordinates all cleaning modules for comprehensive data processing
"""

from typing import Dict, List, Optional
try:
    # Package imports (when used as module)
    from .bom_cleaner import BOMCleaner
    from .column_standardizer import ColumnStandardizer
    from .numeric_cleaner import NumericCleaner
    from .date_cleaner import DateCleaner
    from .currency_handler import CurrencyHandler
    from .data_validator import DataValidator
    from .quality_checker import QualityChecker
except ImportError:
    # Direct imports (when running as script)
    from bom_cleaner import BOMCleaner
    from column_standardizer import ColumnStandardizer
    from numeric_cleaner import NumericCleaner
    from date_cleaner import DateCleaner
    from currency_handler import CurrencyHandler
    from data_validator import DataValidator
    from quality_checker import QualityChecker

class DataCleaner:
    """
    Main data cleaning orchestrator
    Coordinates modular cleaning pipeline for uniform, clean data structure
    """
    
    def __init__(self):
        # Initialize all cleaning modules
        self.bom_cleaner = BOMCleaner()
        self.column_standardizer = ColumnStandardizer()
        self.numeric_cleaner = NumericCleaner()
        self.date_cleaner = DateCleaner()
        self.currency_handler = CurrencyHandler()
        self.data_validator = DataValidator()
        self.quality_checker = QualityChecker()
    
    def clean_parsed_data(self, parsed_data: Dict, template_config: Dict = None) -> Dict:
        """
        Main cleaning function - transforms raw parsed data into clean, uniform structure
        
        Args:
            parsed_data: Raw data from CSV parser
            template_config: Template configuration for cleaning hints
            
        Returns:
            Dict with cleaned data structure including updated column mapping
        """
        try:
            print(f"\nðŸ§¹ STARTING DATA CLEANING")
            print(f"   ðŸ“Š Input: {parsed_data.get('row_count', 0)} rows")
            
            if not parsed_data.get('success', False) or not parsed_data.get('data'):
                return {
                    'success': False,
                    'error': 'Invalid input data for cleaning'
                }
            
            # Step 1: Focus on target data only (remove unwanted rows/columns)
            focused_data = self._focus_target_data(
                parsed_data['data'], 
                parsed_data.get('headers', []),
                template_config
            )
            
            # Step 2: Clean BOM characters from column names (IMPROVED - should use proper encoding)
            bom_cleaned_data = self.bom_cleaner.clean_bom_from_data(focused_data)
            
            # Step 3: Clean and standardize column names
            standardized_data, column_name_mapping = self.column_standardizer.standardize_columns(
                bom_cleaned_data, template_config
            )
            
            # Step 4: Add currency column if missing
            currency_added_data = self.currency_handler.add_currency_column(
                standardized_data, template_config
            )
            
            # Step 5: Clean numeric columns (amounts, balances, etc.)
            numeric_cleaned_data = self.numeric_cleaner.clean_numeric_columns(currency_added_data)
            
            # Step 6: Clean date columns
            date_cleaned_data = self.date_cleaner.clean_date_columns(numeric_cleaned_data)
            
            # Step 7: Remove empty/invalid rows
            valid_data = self.data_validator.remove_invalid_rows(date_cleaned_data)
            
            # Step 8: Create updated column mapping for transformation
            updated_column_mapping = self.column_standardizer.create_cashew_mapping(
                template_config, column_name_mapping
            )
            
            # Step 9: Quality assessment
            quality_report = self.quality_checker.check_data_quality(valid_data)
            
            print(f"   âœ… Cleaning complete: {len(valid_data)} clean rows")
            print(f"   ðŸ—ºï¸ Updated column mapping: {updated_column_mapping}")
            
            return {
                'success': True,
                'data': valid_data,
                'row_count': len(valid_data),
                'updated_column_mapping': updated_column_mapping,
                'quality_report': quality_report,
                'cleaning_summary': {
                    'original_rows': parsed_data.get('row_count', 0),
                    'final_rows': len(valid_data),
                    'rows_removed': parsed_data.get('row_count', 0) - len(valid_data),
                    'numeric_columns_cleaned': self._count_numeric_columns(valid_data),
                    'date_columns_cleaned': self._count_date_columns(valid_data),
                    'currency_column_added': 'Currency' in valid_data[0] if valid_data else False,
                    'quality_grade': quality_report.get('completeness', {}).get('grade', 'Unknown')
                }
            }
            
        except Exception as e:
            print(f"   âŒ Cleaning error: {str(e)}")
            import traceback
            print(f"   ðŸ“š Traceback: {traceback.format_exc()}")
            return {
                'success': False,
                'error': f'Data cleaning failed: {str(e)}'
            }
    
    def _focus_target_data(self, data: List[Dict], headers: List[str], template_config: Dict = None) -> List[Dict]:
        """
        Step 1: Focus on target data only - remove unwanted columns and rows
        """
        print(f"   ðŸŽ¯ Step 1: Focusing target data")
        
        if not data:
            return []
        
        # Get column mapping from template if available
        column_mapping = {}
        if template_config and 'column_mapping' in template_config:
            column_mapping = template_config['column_mapping']
        
        # Identify target columns (mapped columns + common transaction columns)
        target_columns = set()
        
        # Add columns from mapping
        for source_col in column_mapping.values():
            if source_col:  # Skip empty mappings
                target_columns.add(source_col)
        
        # Add common transaction columns (case-insensitive)
        common_columns = ['timestamp', 'date', 'type', 'description', 'amount', 'balance', 
                         'currency', 'exchange_amount', 'exchange_currency', 'fee', 'id', 'reference']
        
        for col in headers:
            col_lower = col.lower()
            if any(common in col_lower for common in common_columns):
                target_columns.add(col)
        
        # If no specific targets found, keep all columns
        if not target_columns:
            target_columns = set(headers)
        
        print(f"      ðŸ“‹ Target columns: {sorted(target_columns)}")
        
        # Filter data to only include target columns
        focused_data = []
        for row in data:
            focused_row = {}
            for col in target_columns:
                if col in row:
                    focused_row[col] = row[col]
            
            # Only include rows that have at least some meaningful data
            if any(str(value).strip() for value in focused_row.values()):
                focused_data.append(focused_row)
        
        print(f"      âœ… Focused data: {len(focused_data)} rows, {len(target_columns)} columns")
        return focused_data
    
    def _count_numeric_columns(self, data: List[Dict]) -> int:
        """Count numeric columns in cleaned data"""
        if not data:
            return 0
        
        numeric_keywords = ['amount', 'balance', 'exchange_amount', 'fee', 'total']
        sample_row = data[0]
        return len([col for col in sample_row.keys() 
                   if any(keyword in col.lower() for keyword in numeric_keywords)])
    
    def _count_date_columns(self, data: List[Dict]) -> int:
        """Count date columns in cleaned data"""
        if not data:
            return 0
        
        date_keywords = ['date', 'timestamp', 'created_at', 'processed_at']
        sample_row = data[0]
        return len([col for col in sample_row.keys() 
                   if any(keyword in col.lower() for keyword in date_keywords)])


# Test the modular data cleaner
if __name__ == "__main__":
    cleaner = DataCleaner()
    
    # Test with sample NayaPay-like data
    sample_parsed_data = {
        'success': True,
        'headers': ['TIMESTAMP', 'TYPE', 'DESCRIPTION', 'AMOUNT', 'BALANCE'],
        'data': [
            {
                'TIMESTAMP': '02 Feb 2025 11:17 PM',
                'TYPE': 'Raast Out',
                'DESCRIPTION': 'Transfer to Someone',
                'AMOUNT': '-5,000',
                'BALANCE': '872.40'
            },
            {
                'TIMESTAMP': '03 Feb 2025 12:15 PM',
                'TYPE': 'IBFT In',
                'DESCRIPTION': 'Transfer from Someone',
                'AMOUNT': '+50,000',
                'BALANCE': '50,872.40'
            }
        ],
        'row_count': 2
    }
    
    # Test with sample template config for NayaPay
    template_config = {
        'column_mapping': {
            'Date': 'TIMESTAMP',
            'Amount': 'AMOUNT',
            'Title': 'DESCRIPTION',
            'Note': 'TYPE'
        },
        'bank_name': 'NayaPay'
    }
    
    print("ðŸ§ª Testing Modular Data Cleaner")
    result = cleaner.clean_parsed_data(sample_parsed_data, template_config)
    
    print(f"\nðŸ“Š Cleaning Result:")
    import json
    print(json.dumps(result, indent=2, default=str))
